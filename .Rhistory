linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
}
print(c(i,j))
}
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
}
print(c(i,j))
}
}
postbody
to.remove
gsub("\t", "", postbody)
gsub("\\t", "", postbody)
postbody
postbody[8,3]
m <- postbody[8,3]
mn
m
gsub("\n", "", m)
postbody[,1]
gsub("\n", "", postbody[,1])
gsub("\t", "",gsub("\n", "", postbody[,1]))
gsub("\t", "",gsub("\n", "", postbody[,]))
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}}
postbody
to.remove
wordcloud(postbody)
require(wordcloud)
View(postbody)
wordcloud(postbody)
?save
wordcloud(postbody, file = "Momentumpostbody")
save(postbody, file = "Momentumpostbody")
a <- load(postbody)
?load
a <- data.frame(load(postbody))
a <- load("postbody")
getwd()
saveRDS(postbody, "postbody.rds")
home <- "C:/Users/Veldrin/Documents/"
source(paste(home, "GitHub/US-Mapping/Shiny/Haversine.R", sep = ""))
closest <- 2
# Gets and cleans addresses ----
addresses <- data.frame(read.csv(paste(home, "GitHub/USClientGeomapping/MyriadClientAddresses.csv", sep = "")))
addresses <- addresses[,!grepl("X", colnames(addresses))]
addresses <- addresses[which(!is.na(addresses$lon)),]
colnames(addresses)[1] <- "address"
# Gets and cleans client data ----
clients <- data.frame(read.csv(paste(home, "GitHub/US-Mapping/Shiny/data/ClientIncome.csv", sep = "")))
clients$fulladdress <- paste(clients$ResAddress1,
clients$ResAddress2,
clients$ResAddress3,
clients$ResAddress4,
clients$ResAddress5,
clients$ResAddress6,
sep = "")
clients <- clients[which(clients$fulladdress != ''),]
clients$fulladdress <- paste(clients$ResAddress1,
clients$ResAddress2,
clients$ResAddress3,
clients$ResAddress4,
clients$ResAddress5,
clients$ResAddress6,
sep = " ")
clients$ResAddress1 <- NULL
clients$ResAddress2 <- NULL
clients$ResAddress3 <- NULL
clients$ResAddress4 <- NULL
clients$ResAddress5 <- NULL
clients$ResAddress6 <- NULL
# creates usable data set----
merged.data <- merge(clients, addresses, by.x = "fulladdress", by.y = "address")
usable.data <- merged.data[!is.na(merged.data$lon),]
usable.data <- usable.data[which(usable.data$country == "south africa"),c("PolicyNo", "Income_Combined", "lon", "lat", "province")]
usable.data <- usable.data[which(usable.data$Income_Combined > 1),]
# Imports store information ----
gyms <- data.frame(read.csv(paste(home, "GitHub/US-Mapping/Shiny/data/Gyms.csv", sep = "")))
WW <- data.frame(read.csv(paste(home, "GitHub/US-Mapping/Shiny/data/ww.csv", sep = "")))
Disc <- data.frame(read.csv(paste(home, "GitHub/US-Mapping/Shiny/data/disc.csv", sep = "")))
schools <- data.frame(read.csv(paste(home, "GitHub/US-Mapping/Shiny/data/Schools.csv", sep = "")))
pnp <- data.frame(read.csv(paste(home, "GitHub/US-Mapping/Shiny/data/PnP.csv", sep = "")))
nandos <- data.frame(read.csv(paste(home, "GitHub/US-Mapping/Shiny/data/nandos.csv", sep = "")))
gyms <- cbind("gyms", gyms[which(!is.na(gyms$lon )), c("lon", "lat"),])
WW <- cbind("ww", WW[which(!is.na(WW$lon)), c("lon", "lat")])
Disc <- cbind("disc", Disc[which(!is.na(Disc$lon)), c("lon", "lat")])
schools <- cbind("schools", schools[which(!is.na(schools$lon)), c("lon", "lat")])
pnp <- cbind("PnP", pnp[which(!is.na(pnp$lon)), c("lon", "lat")])
nandos <- cbind("Nandos", nandos[which(!is.na(nandos$lon)), c("lon", "lat")])
colnames(gyms) <- c("type", "lon", "lat")
colnames(WW) <- c("type", "lon", "lat")
colnames(Disc) <- c("type", "lon", "lat")
colnames(schools) <- c("type", "lon", "lat")
colnames(pnp) <- c("type", "lon", "lat")
colnames(nandos) <- c("type", "lon", "lat")
# creates list of data frame and defines column names based on POIs ----
poi <- list(gyms, WW, Disc, schools, pnp, nandos)
closest.pois <- data.frame(matrix(ncol = length(poi)*closest))
for (i in 1:(length(poi)*closest)) {
colnames(closest.pois)[i] <- paste(as.character(poi[[ceiling(i/closest)]]$type[1]), (i + closest-1) %% closest +1, sep = "")
}
# calculates the distance between clients and closest POIs----
system.time(for (i in 1:nrow(usable.data)){
for (j in 1:length(poi)) {
for(k in 1:nrow(poi[[j]])) {
poi[[j]]$dist[k] <- Haversine(c(usable.data$lon[i], usable.data$lat[i]), c(poi[[j]]$lon[k], poi[[j]]$lat[k]))
}
closest.pois[i,1:(closest) + (j-1)*closest] <- poi[[j]][order(poi[[j]]$dist[which(poi[[j]]$dist >0)], decreasing = F) ,]$dist[1:closest]
}
print(c(i, nrow(usable.data)))
})
# removes policy numbers and duplicate rows
combined.data <- unique(cbind(usable.data, closest.pois)[,2:as.numeric(ncol(cbind(usable.data, closest.pois)-1))])
combined.data
str(combined.data)
head(combined.data[,5:16])
head(combined.data[,5:16]) < 25
a <- head(combined.data[,5:16], 100) < 25
a
a[5,]
F %%in%% a[5,]
F in a[5,]
FALSE in a[5,]
F %in% a
F %in% a[5,]
a[5,]
a[6,]
F %in% a[6,]
F %in% a
F %in% a[]
F %in% a[,]
sapply(a, function (x) F %in% a[x,])
sapply(a,function(x) F %in% a )
str(combined.data)
F %in% combined.data[i,5:16]
for (i in 1:nrow(combined.data)){
combined.data$within25[i] <- F %in% combined.data[i,5:16]
}
str(combined.data)
head(combined.data,100)
combined.data[i,5:16] < 25
F %in% (combined.data[i,5:16] < 25)
for (i in 1:nrow(combined.data)){
combined.data$within25[i] <- F %in% (combined.data[i,5:16] < 25)
}
head(combined.data,100)
for (i in 1:nrow(combined.data)){
combined.data$within25[i] <- F %in% (combined.data[i,5:16] < 50)
}
for (i in 1:nrow(combined.data)){
combined.data$within25[i] <- F %in% (combined.data[i,5:16] > 50)
}
head(combined.data,100)
combined.data$within25 <- NULL
!(F %in% (combined.data[i,5:16] < 50))
for (i in 1:nrow(combined.data)){
combined.data$withinradius[i] <- !(F %in% (combined.data[i,5:16] < 50))
}
head(combined.data,100)
length(combined.data$withinradius == T)
combined.data2 <- combined.data[which(combined.data$within25 == T),]
combined.data2
combined.data2 <- combined.data[which(combined.data$withinradius == T),]
combined.data2
b <- sample(nrow(combined.data2), nrow(combined.data2)*.25)
btest <- (1:nrow(combined.data2) %in% test.rows)
btrain <- !btest
b <- sample(nrow(combined.data2), nrow(combined.data2)*.25)
btest <- (1:nrow(combined.data2) %in% b)
btrain <- !btest
plot(combined.data2)
str(combined.data2)
str(combined.data2[,5:16])
plot(combined.data2[,5:16])
combined.data2[,5:16]
plot(combined.data2[,c(1,5:16)])
plot(combined.data2[,c(1,5:16)])
plot(combined.data2$Income_Combined)
?quantile
quantile(combined.data2$Income_Combined)
quantile(combined.data2$Income_Combined, c(0,1,.05))
quantile(combined.data2$Income_Combined, c(0.95,.05))
?quantile
abline(quantile(combined.data2$Income_Combined, probs = 0.95))
abline(h = quantile(combined.data2$Income_Combined, probs = 0.95))
abline(h = quantile(combined.data2$Income_Combined, probs = 0.995))
abline(h = quantile(combined.data2$Income_Combined, probs = 0.99995))
abline(h = quantile(combined.data2$Income_Combined, probs = 0.995))
abline(h = quantile(combined.data2$Income_Combined, probs = 0.995, col = "red"))
abline(h = quantile(combined.data2$Income_Combined, probs = 0.9995, col = "red"))
abline(h = quantile(combined.data2$Income_Combined, probs = 0.99995, col = "red"))
combined.data2[which(combined.data2$Income_Combined < quantile(combined.data2$Income_Combined, probs = 0.99995, col = "red"),)]
which(combined.data2$Income_Combined < quantile(combined.data2$Income_Combined, probs = 0.99995)
which(combined.data2$Income_Combined < quantile(combined.data2$Income_Combined, probs = 0.99995)
which(combined.data2$Income_Combined < quantile(combined.data2$Income_Combined, probs = 0.99995))
combined.data2[which(combined.data2$Income_Combined < quantile(combined.data2$Income_Combined, probs = 0.99995)),]
combined.data2 <- combined.data2[which(combined.data2$Income_Combined < quantile(combined.data2$Income_Combined, probs = 0.99995)),]
plot(combined.data2[,c(1,5:16)])
?plot
head(cars)
plot(dist~speed,data=cars)  ## Formula notation
plot(cars)
plot(cars$speed,cars$dist,col="blue")
abline(h=15,col="red")
#'
abline(v=15, col="darkblue",lwd=2)
qplot(mpg, data = mtcars)
require(ggplot2)
qplot(mpg, data = mtcars)
qplot(x = hp, y = mpg, data = mtcars)
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg, shape=as.factor(gear))
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg)
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg, geom="point")
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg, geom=c("point","smooth"))
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg, geom=c("point","smooth"),se=FALSE)
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg, geom=c("point","smooth"),span=1)
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg, geom=c("point","smooth"),span=1)
qplot(x = cut(mtcars$hp,4), y = mpg, data = mtcars, geom="boxplot")
qplot(x = hp, y = mpg, data = mtcars, geom=c("boxplot","jitter"))
qplot(x = cut(mtcars$hp,4), y = mpg, data = mtcars, geom=c("boxplot","jitter"))
qplot(x = hp, y = mpg, data = mtcars, color = cyl, size = mpg, facets = .~ gear)
p <- ggplot(data = mtcars, aes(hp, mpg, label = rownames(mtcars)))
# only takes clients withing 50km stores
for (i in 1:nrow(combined.data)){
combined.data$withinradius[i] <- !(F %in% (combined.data[i,5:16] < 25))
}
combined.data2 <- combined.data[which(combined.data$withinradius == T),]
combined.data2 <- combined.data2[which(combined.data2$Income_Combined < quantile(combined.data2$Income_Combined, probs = 0.99995)),]
b <- sample(nrow(combined.data2), nrow(combined.data2)*.25)
btest <- (1:nrow(combined.data2) %in% b)
btrain <- !btest
plot(combined.data2)
plot(combined.data2[,c(1,5:16)])
plot(combined.data2[,c(1,5:16)])
lat <- readWave("C:/shared folder/09_Lateralus.wav", from = 140, to = 150, units= "seconds")
timer(lat, f=22050, threshold=5, msmooth=c(40,0), bty="l", colval="blue")
require(tuneR)
require(seewave)
lat <- readWave("C:/shared folder/09_Lateralus.wav", from = 140, to = 150, units= "seconds")
timer(lat, f=22050, threshold=5, msmooth=c(40,0), bty="l", colval="blue")
plot(lat)
timer(cock, f=22050, threshold=5, msmooth=c(40,0), bty="l", colval="blue")
data(onri)
data(orni)
timer(cock, f=22050, threshold=5, msmooth=c(40,0), bty="l", colval="blue")
timer(orni, f=22050, threshold=5, msmooth=c(40,0), bty="l", colval="blue")
lat <- readWave("C:/shared folder/09_Lateralus.wav", from = 140, to = 142, units= "seconds")
timer(lat, f=22050, threshold=5, msmooth=c(40,0), bty="l", colval="blue")
listen(lat)
timer(lat, f=22050, threshold=60, msmooth=c(40,0), bty="l", colval="blue")
lat <- readWave("C:/shared folder/09_Lateralus.wav", from = 140, to = 152, units= "seconds")
listen(lat)
listen(lat)
lat <- readWave("C:/shared folder/09_Lateralus.wav", from = 140, to = 152, units= "seconds")
lat <- readWave("C:/shared folder/09_Lateralus.wav", from = 140, to = 152, units= "seconds")
listen(lat)
lat <- readWave("C:/shared folder/09_Lateralus.wav", from = 150, to = 155, units= "seconds")
listen(lat)
timer(lat, f=22050, threshold=60, msmooth=c(40,0), bty="l", colval="blue")
install.packages("twitteR")
require(twitteR)
?twitteR
require(twitteR)
?twitteR
source('~/.active-rstudio-document')
twitteR
?scan
private <- scan("C:/Users/Veldrin/Desktop/hospitals/private.txt")
private <- scan("C:/Users/Veldrin/Desktop/hospitals/private.txt",
what = character(0))
privat
private
scan("C:/Users/Veldrin/Desktop/hospitals/private.txt",
what = character(1))
private <- scan("C:/Users/Veldrin/Desktop/hospitals/private.txt",
what = character(0),
sep = "\n")
private
state <- scan("C:/Users/Veldrin/Desktop/hospitals/state.txt",
what = character(0),
sep = "\n")
private <- data.frame(private)
colnames(private) <- "Private.Hospital"
loc <- list()
for (i in 1:nrow(private)){
loc[[i]] <- geocode(private$Private.Hospital[i], output = 'more')
private$lon[i] <- loc[[i]]$lon
private$lat[i] <- lon[[i]]$lat
private$country[i] <- if(is.na(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
require(ggmap)
for (i in 1:nrow(private)){
loc[[i]] <- geocode(private$Private.Hospital[i], output = 'more')
private$lon[i] <- loc[[i]]$lon
private$lat[i] <- lon[[i]]$lat
private$country[i] <- if(is.na(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
for (i in 1:nrow(private)){
loc[[i]] <- geocode(as.character(private$Private.Hospital[i]), output = 'more')
private$lon[i] <- loc[[i]]$lon
private$lat[i] <- lon[[i]]$lat
private$country[i] <- if(is.na(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
i <- 1
loc[[i]] <- geocode(as.character(private$Private.Hospital[i]), output = 'more')
private$lon[i] <- loc[[i]]$lon
private$lat[i] <- lon[[i]]$lat
for (i in 1:nrow(private)){
loc[[i]] <- geocode(as.character(private$Private.Hospital[i]), output = 'more')
private$lon[i] <- loc[[i]]$lon
private$lat[i] <- loc[[i]]$lat
private$country[i] <- if(is.na(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
for (i in 1:nrow(private)){
loc[[i]] <- geocode(as.character(private$Private.Hospital[i]), output = 'more')
private$lon[i] <- loc[[i]]$lon
private$lat[i] <- loc[[i]]$lat
private$country[i] <- if(is.null(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
state <- data.frame(state)
colnames(state) <- "State.Hospital"
loc <- list()
for (i in 1:nrow(state)){
loc[[i]] <- geocode(as.character(state$Private.Hospital[i]), output = 'more')
state$lon[i] <- loc[[i]]$lon
state$lat[i] <- loc[[i]]$lat
state$country[i] <- if(is.null(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
write.csv(private, "private.csv", row.names = F)
write.csv(private, "state.csv", row.names = F)
write.csv(private, "private.csv", row.names = F)
write.csv(state, "state.csv", row.names = F)
private
state
state <- data.frame(state)
colnames(state) <- "State.Hospital"
loc <- list()
for (i in 1:nrow(state)){
loc[[i]] <- geocode(as.character(state$Private.Hospital[i]), output = 'more')
state$lon[i] <- loc[[i]]$lon
state$lat[i] <- loc[[i]]$lat
state$country[i] <- if(is.null(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
state
for (i in 1:nrow(state)){
loc[[i]] <- geocode(as.character(state$State.Hospital[i]), output = 'more')
state$lon[i] <- loc[[i]]$lon
state$lat[i] <- loc[[i]]$lat
state$country[i] <- if(is.null(loc[[i]]$country)) NA else loc[[i]]$country
print(i)
}
write.csv(private, "private.csv", row.names = F)
write.csv(state, "state.csv", row.names = F)
getwd()
training.set <- read.scv("C:/Github/Titanic/data/train.scv")
training.set <- read.csv("C:/Github/Titanic/data/train.scv")
training.set <- read.csv("C:/Github/Titanic/data/train.csv")
training.set <- read.csv("C:/Github/Titanic/data/train.csv")
genderclassmodel <- read.csv("C:/Github/Titanic/data/genderclassmodel.csv")
gendermodel <- read.csv("C:/Github/Titanic/data/gendermodel.csv")
training.set
head(training.set, 5)
head(genderclassmodel,5)
head(gendermodel,5)
nrow(training.set)
nrow(genderclassmodel)
nrow(gendermodel)
head(training.set, 10)
ts <- read.csv("C:/Github/Titanic/data/train.csv")
nrow(ts)
head(ts, 10)
ts[which(ts$SibSp > 0),]
head(ts[which(ts$SibSp > 0),])
require(twitteR)
require(plyr)
require(wordcloud)
require(tm)
#PC
setwd("C:/Users/Veldrin/Documents/GitHub/SATwitteR")
#Laptop
setwd("C:/Users/anmarais/Desktop/GitHub/SATwitteR")
all.tweets <- readRDS("tweets.RDS")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
consumer_key <- 'tzpuerQtZ4PGi0jqOgNg77y6w'
consumer_secret <- 'YJwFwkfvZQ3SNdIVVoASZPspgt8b7esLp8Jqp4qk7ldWINGDin'
access_token <- '1592761717-yWRgnXsVOimayc8N5Gov9lZDSnM6Ui2kBYQOhaK'
access_secret <- 'H88PH4tiiDJg2Kir5NkcrhEw3sf0PSqrK5XGIwRKGHqYx'
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
t.handles <- data.frame(read.csv(file.path(getwd(), "/data/twitterhandles.csv")))
all.tweets <- list()
user.tweets <- data.frame()
combined.tweets <- list()
# for (i in 1:nrow(t.handles)) {
for (i in 1:15) {
#user.tweets <- userTimeline(as.character(t.handles[i,1]), n = 200)
all.tweets[[i]] <- try(userTimeline(as.character(t.handles[i,1]), n = 200))
}
k <- 1
# for (i in 1:nrow(t.handles)) {
for (i in 1:15) {
if (length(all.tweets[[i]]) > 1) {
user.tweets <- data.frame()
for (j in 1:length(all.tweets[[i]])) {
user.tweets[j,1] <- as.character(all.tweets[[i]][[j]]$screenName)
user.tweets[j,2] <- as.character(all.tweets[[i]][[j]]$text)
user.tweets[j,3] <- as.character(as.Date(all.tweets[[i]][[j]]$created))
}
combined.tweets[[k]] <- user.tweets
k <- k +1
}
}
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
#remove all direct tweets
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
april.tweets <- df[which(df$TweetDate >= "2015-04-01"),]
# removes emoticon bullshit
april.tweets$Tweet <- sapply(april.tweets$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
april.tweets$Tweet <- sapply(april.tweets$Tweet, function(x) gsub("\n", "", april.tweets$Tweet))
tweet.corpus <- Corpus(VectorSource(april.tweets$Tweet))
tdm <- TermDocumentMatrix(tweet.corpus)
tweet.corpus
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
require(wordcloud)
wordcloud(tweet.corpus)
stopwords("en")
"the" %in% stopwords("en")
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
wordcloud(tweet.corpus)
tweet.corpus
