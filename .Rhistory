tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tweet.corpus <- tm_map(tweet.corpus, removeWords, "the")
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,200)
wordcloud(names(v),v,c(4,.2),2,200)
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tweet.corpus <- tm_map(tweet.corpus, removeWords, "the")
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
names(head(v,2))
tweet.corpus <- Corpus(VectorSource(df$Tweet), list(reader=readPlain))
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tweet.corpus <- tm_map(tweet.corpus, removeWords, "the")
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
#'
m <- as.matrix(tdm)
#'
v <- sort(rowSums(m),decreasing=TRUE)
#'
#'
wordcloud(names(v),v,c(4,.2),2,200)
tweet.corpus <- Corpus(df$Tweet, list(reader=readPlain))
?Corpus
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tweet.corpus <- tm_map(tweet.corpus, removeWords, "the")
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,200)
df$Tweet
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
#remove all direct tweets
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
# removes emoticon bullshit
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
gregexpr("the", df$Tweet)
as.character(gregexpr("the", df$Tweet))
df$Tweet <- as.character(df$Tweet)
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tweet.corpus <- tm_map(tweet.corpus, removeWords, "the")
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,2,200)
wordcloud(names(v),v,c(4,.2),2,100)
gregexpr("the", df$Tweet)
df$Tweet
df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T))
df$Tweet
?tm_map
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
# removes emoticon bullshit
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
#df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T))
df$Tweet <- as.character(df$Tweet)
#comments <- tm_map(comments , tolower)
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
#df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T))
#comments <- tm_map(comments , tolower)
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
head(v)
tdm
tweet.corpus
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tdm <- TermDocumentMatrix(tweet.corpus,control=list(weighting=weightTfIdf))
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
head(v)
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("en"))
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T))
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
as.character(gregexpr("laughton", df$Tweet))
as.character(gregexpr("laughton", df$Tweet, ignore.case = T))
df$Tweet[gregexpr("laughton", df$Tweet, ignore.case = T),]
df$Tweet[gregexpr("laughton", df$Tweet, ignore.case = T)]
df$Tweet[as.character(gregexpr("laughton", df$Tweet, ignore.case = T))]
df$Tweet[as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T))]
as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T))
which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1)
df$Tweet[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1)]
df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), 1:2]
df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ]
a <- df[1445,2]
a
df[1444,]
df[144,]
df[1245,]
df[1225,]
df[1255,]
df[1256,]
df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ]
row.names(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ])
df[1250,]
df[600,]
row.names(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ])[5,]
df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ]
head(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ],1)
head(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ],1)[,1]
head(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ],1)[,2]
a <- head(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ],1)[,2]
a
gregexpr("#", a)
gregexpr("#[a-z]", a)
gregexpr("#?[a-z]", a)
gregexpr("#? $", a)
gregexpr(" $", a)
gregexpr("#(\\d|\\w)+", a)
regmatches("#(\\d|\\w)+", a)
regmatches(a, "#(\\d|\\w)+")
regmatches(a,gregexpr("#(\\d|\\w)+", a))
?regmatches
regmatches(df$Tweet,gregexpr("#(\\d|\\w)+", df$Tweet))
b <- regmatches(df$Tweet,gregexpr("#(\\d|\\w)+", df$Tweet))
as.character(v)
as.character(b)
b[which(as.character(b) != character(0))]
b[which(as.character(b) != "character(0)")]
table(b[which(as.character(b) != "character(0)")])
data.frame(b[which(as.character(b) != "character(0)")])
c <- b[which(as.character(b) != "character(0)")]
d <- ldply(c, data.frame)
d
c <- b[which(as.character(b) != "character(0)")]
c
unique(rapply(c, function(x) head(x, 1)))
unique(rapply(c, function(x) head(x, 5)))
unique(rapply(c, function(x) head(x, 20)))
?rapply
unlist(c)
unique(unlist(c))
table(unlist(c))
?table
d <- table(unlist(c))
order(d, decreasing = T)
e <- order(d, decreasing = T)
d[e]
e <- order(d, decreasing = T)[1:10]
d[e]
all.tweets <- list()
user.tweets <- data.frame()
combined.tweets <- list()
for (i in 1:nrow(t.handles)) {
#user.tweets <- userTimeline(as.character(t.handles[i,1]), n = 200)
all.tweets[[i]] <- try(userTimeline(as.character(t.handles[i,1]), n = 200))
}
k <- 1
for (i in 1:nrow(t.handles)) {
if (length(all.tweets[[i]]) > 1) {
user.tweets <- data.frame()
for (j in 1:length(all.tweets[[i]])) {
user.tweets[j,1] <- as.character(all.tweets[[i]][[j]]$screenName)
user.tweets[j,2] <- as.character(all.tweets[[i]][[j]]$text)
user.tweets[j,3] <- as.character(as.Date(all.tweets[[i]][[j]]$created))
}
combined.tweets[[k]] <- user.tweets
k <- k +1
}
}
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
#remove all direct tweets
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
# removes emoticon bullshit
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T)) #removeWords is buggy now, doesnt remove "the" when it's the first word of the string
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
a <- head(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ],1)[,2]
b <- regmatches(df$Tweet,gregexpr("#(\\d|\\w)+", df$Tweet))
c <- b[which(as.character(b) != "character(0)")]
d <- table(unlist(c))
e <- order(d, decreasing = T)[1:10]
d[e]
b <- regmatches(df$Tweet,gregexpr("#(\\d|\\w)+", df$Tweet, ignore.case = T))
c <- b[which(as.character(b) != "character(0)")]
d <- table(unlist(c))
e <- order(d, decreasing = T)[1:10]
d[e]
tm_map(d[e], tolower)
head(m)
head(v)
e <- order(d, decreasing = T)[1:5]
d[e]
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
wordcloud(names(v),v,c(4,.2),2,100)
head)v
head(v)
d[e]
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
head(v)
a <- head(df[which(as.numeric(gregexpr("laughton", df$Tweet, ignore.case = T)) != -1), ],1)[,2]
b <- regmatches(df$Tweet,gregexpr("#(\\d|\\w)+", df$Tweet))
c <- b[which(as.character(b) != "character(0)")]
d <- table(unlist(c))
e <- order(d, decreasing = T)[1:5]
d[e]
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "the"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
#tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
w
head(v)
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said", "#"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
#tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
head(v)
b
d
tolower(d)
str(d)
attr(d, "dimnames")
attr(d, "dimnames") <- tolower(attr(d, "dimnames"))
tolower(attr(d, "dimnames"))
c
tolower(c)
c(c)
c(d)
d
tolower(d)
unlist(c)
tolower(unlist(c))
d <- table(unlist(tolower(c)))
e <- order(d, decreasing = T)[1:5]
d[e]
e <- order(d, decreasing = T)[1:6]
e <- order(d, decreasing = T)[1:6]
d[e]
gsub(stopwords("english"), df$Tweet, ignore.case = T)
gsub(stopwords("english"), "", df$Tweet, ignore.case = T)
for (i in 1:nrow(t.handles)) {
#user.tweets <- userTimeline(as.character(t.handles[i,1]), n = 200)
all.tweets[[i]] <- try(userTimeline(as.character(t.handles[i,1]), n = 500))
}
k <- 1
for (i in 1:nrow(t.handles)) {
if (length(all.tweets[[i]]) > 1) {
user.tweets <- data.frame()
for (j in 1:length(all.tweets[[i]])) {
user.tweets[j,1] <- as.character(all.tweets[[i]][[j]]$screenName)
user.tweets[j,2] <- as.character(all.tweets[[i]][[j]]$text)
user.tweets[j,3] <- as.character(as.Date(all.tweets[[i]][[j]]$created))
}
combined.tweets[[k]] <- user.tweets
k <- k +1
}
}
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
#remove all direct tweets
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
# removes emoticon bullshit
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T)) #removeWords is buggy now, doesnt remove "the" when it's the first word of the string
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
#tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
head()
wordcloud(names(v),v,c(4,.2),2,100)
b <- regmatches(df$Tweet,gregexpr("#(\\d|\\w)+", df$Tweet))
c <- b[which(as.character(b) != "character(0)")]
d <- table(unlist(tolower(c)))
e <- order(d, decreasing = T)[1:6]
d[e]
save.image("~/GitHub/SATwitteR/workspace.RData")
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
# removes emoticon bullshit
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T)) #removeWords is buggy now, doesnt remove "the" when it's the first word of the string
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
#tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
head()
wordcloud(names(v),v,c(4,.2),2,100)
b <- regmatches(df$Tweet,gregexpr("#(\\d|\\w)+", df$Tweet))
c <- b[which(as.character(b) != "character(0)")]
d <- table(unlist(tolower(c)))
e <- order(d, decreasing = T)[1:6]
d[e]
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
# removes emoticon bullshit
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T)) #removeWords is buggy now, doesnt remove "the" when it's the first word of the string
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
head()
wordcloud(names(v),v,c(4,.2),2,100)
combined.tweets
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
#remove all direct tweets
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- df[which(df$TweetDate >= "2015-04-01"),]
# removes emoticon bullshit
df$Tweet <- sapply(df$Tweet, function(x) iconv(x,"latin1", "ASCII", sub = ""))
df$Tweet <- sapply(df$Tweet, function(x) gsub("\n", "", x))
df$Tweet <- sapply(df$Tweet, function(x) gsub("the", "", x, ignore.case = T)) #removeWords is buggy now, doesnt remove "the" when it's the first word of the string
tweet.corpus <- Corpus(VectorSource(df$Tweet))
tweet.corpus <- tm_map(tweet.corpus, tolower)
tweet.corpus <- tm_map(tweet.corpus, removeWords, stopwords("english"))
tweet.corpus <- tm_map(tweet.corpus, removeWords, c("&lsquo;", "&rsquo;", "&ldquo;", "&ldquo;", "&ndash", "said"))
#tweet.corpus <- tm_map(tweet.corpus, removePunctuation)
tweet.corpus <- tm_map(tweet.corpus, stripWhitespace)
#tweet.corpus <- tm_map(tweet.corpus, removeNumbers)
tdm <- TermDocumentMatrix(tweet.corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
head()
wordcloud(names(v),v,c(4,.2),2,100)
View(df)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
df <- df[-which(as.character(gregexpr("@", df$Tweet)) != -1),]
df <- ldply(combined.tweets, data.frame)
colnames(df) <- c("ScreenName", "Tweet", "TweetDate")
which(as.character(gregexpr("@", df$Tweet)) != -1)
head(df)
gregexpr("@", head(df$Tweet)))
gregexpr("@", head(df$Tweet))
which(as.character(gregexpr("@", df$Tweet)) != -1)
which(as.numeric(gregexpr("@", df$Tweet)) != -1)
which(as.character(gregexpr("@", df$Tweet)) != "-1"
)
gregexpr("@", df$Tweet)
as.character(gregexpr("@", df$Tweet))
which(as.character(gregexpr("@", df$Tweet)) == "-1")
as.character(gregexpr("@", df$Tweet)) == "-1"
which(as.character(gregexpr("@", df$Tweet)) == "-1")
-which(as.character(gregexpr("@", df$Tweet)) == -1)
as.character(gregexpr("@", df$Tweet)) == -1
